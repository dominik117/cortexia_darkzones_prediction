{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBS-xJR1JVEN"
      },
      "outputs": [],
      "source": [
        "# Install OSMNX only if working on Google Colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    !pip install osmnx\n",
        "    !pip install matplotlib==3.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl7w6-dQqDug",
        "outputId": "7ede83e8-00bb-4101-f405-b6f2a8ea06e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  V2data_6mounts2022.csv.zip\n",
            "  inflating: data.csv                \n",
            "  inflating: __MACOSX/._data.csv     \n"
          ]
        }
      ],
      "source": [
        "# Load datasets if working on Google Colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    file_id = '...'\n",
        "    downloaded = drive.CreateFile({'id':file_id})\n",
        "    downloaded.FetchMetadata(fetch_all=True)\n",
        "    downloaded.GetContentFile(downloaded.metadata['title'])\n",
        "    f = open(\"V2data_6mounts2022.csv.zip\", \"wb\")\n",
        "    f.write(downloaded.content.getbuffer())\n",
        "    f.close()\n",
        "    !unzip V2data_6mounts2022.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g-fT2Ow_RM4b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import sys\n",
        "import osmnx\n",
        "import requests\n",
        "import pickle\n",
        "import cloudpickle as cp\n",
        "from urllib.request import urlopen\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    r = requests.get('https://raw.githubusercontent.com/dominik117/cortexia-darkzones-prediction/main/src/helper_scripts/data_processor.py')\n",
        "    with open('data_processor.py', 'w') as f:\n",
        "        f.write(r.text)\n",
        "        import data_processor\n",
        "    r = requests.get('https://raw.githubusercontent.com/dominik117/cortexia-darkzones-prediction/main/src/helper_scripts/darkzone_creator.py')\n",
        "    with open('darkzone_creator.py', 'w') as f:\n",
        "        f.write(r.text)\n",
        "        import darkzone_creator\n",
        "else:\n",
        "    sys.path.insert(1, '../../src/')\n",
        "    import helper_scripts.data_processor as data_processor\n",
        "    import helper_scripts.dz_creator as darkzone_creator\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQaIlaszqDuo"
      },
      "source": [
        "## Dataset Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6pHwDoOZqDur"
      },
      "outputs": [],
      "source": [
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB: df_main_url = '/content/data.csv'\n",
        "else: df_main_url = '../../data/datav2.csv'\n",
        "df_main = pd.read_csv(df_main_url, dtype = {'place.id': object})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from random import randint\n",
        "def encrypt_edge_id(x):\n",
        "    if x != x:\n",
        "        return np.nan\n",
        "    foo = tuple(x[1:-1].split(', ')[0:2])\n",
        "    foo1 = randint(10**(len(foo[0])-1), 10**len(foo[0])-1) \n",
        "    foo2 = randint(10**(len(foo[1])-1), 10**len(foo[1])-1) \n",
        "    return f\"({foo1}, {foo2}, 0)\"\n",
        "\n",
        "edges = list(df_main[\"edge.id\"].unique())\n",
        "encrypted_edges = {}\n",
        "for edge in edges:\n",
        "    encrypted_edges[edge] = encrypt_edge_id(edge)\n",
        "\n",
        "df_main[\"edge.id\"] = df_main[\"edge.id\"].map(encrypted_edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_darkzones = darkzone_creator.create_darkzones(df_main)\n",
        "# Runtime ~2 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>suitcase.id</th>\n",
              "      <th>date.utc</th>\n",
              "      <th>edge.id</th>\n",
              "      <th>edge.osmid</th>\n",
              "      <th>place.id</th>\n",
              "      <th>osm.highway</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>10</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>16</th>\n",
              "      <th>19</th>\n",
              "      <th>21</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>39</th>\n",
              "      <th>49</th>\n",
              "      <th>61</th>\n",
              "      <th>63</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RLftkn8B6D05RDJPRFzw</td>\n",
              "      <td>101</td>\n",
              "      <td>2022-03-16 13:31:23.556000</td>\n",
              "      <td>(66861445, 5777577020, 0)</td>\n",
              "      <td>148827821.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>secondary</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2rftkn8B6D05RDJPg1zA</td>\n",
              "      <td>101</td>\n",
              "      <td>2022-03-16 13:31:40.397000</td>\n",
              "      <td>(4784490177, 879290314, 0)</td>\n",
              "      <td>249810956.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>secondary</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7Lftkn8B6D05RDJPilxI</td>\n",
              "      <td>84</td>\n",
              "      <td>2022-03-16 13:31:42.588000</td>\n",
              "      <td>(5024071332, 2468498684, 0)</td>\n",
              "      <td>148744643.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>footway</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>r_Ttkn8BECWPrCgui1Ov</td>\n",
              "      <td>102</td>\n",
              "      <td>2022-03-16 13:18:31.370000</td>\n",
              "      <td>(131242325, 366524790, 0)</td>\n",
              "      <td>25371931.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>footway</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abftkn8B6D05RDJPkl0B</td>\n",
              "      <td>84</td>\n",
              "      <td>2022-03-16 13:31:44.839000</td>\n",
              "      <td>(4112634135, 6927774285, 0)</td>\n",
              "      <td>680591900.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>secondary</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1380547</th>\n",
              "      <td>GdQwSIEB6D05RDJPRgFx</td>\n",
              "      <td>110</td>\n",
              "      <td>2022-06-09 11:18:30.202000</td>\n",
              "      <td>(8859143893, 7271978688, 0)</td>\n",
              "      <td>218421857.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>residential</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1380548</th>\n",
              "      <td>HdQwSIEB6D05RDJPRwGz</td>\n",
              "      <td>107</td>\n",
              "      <td>2022-06-09 11:18:34.652000</td>\n",
              "      <td>(392518067, 121526083, 0)</td>\n",
              "      <td>25307428.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1380549</th>\n",
              "      <td>i7MwSIEBjBK6gFa3V62V</td>\n",
              "      <td>105</td>\n",
              "      <td>2022-06-09 11:16:05.803000</td>\n",
              "      <td>(190115287, 9768290867, 0)</td>\n",
              "      <td>182402103.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>unclassified</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1380550</th>\n",
              "      <td>5hHYTIEBECWPrCguIrVd</td>\n",
              "      <td>70</td>\n",
              "      <td>2022-06-10 09:00:06.043000</td>\n",
              "      <td>(6238636487, 231741978, 0)</td>\n",
              "      <td>794466424.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>secondary</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1380551</th>\n",
              "      <td>u7fXTIEBjBK6gFa3lpXL</td>\n",
              "      <td>84</td>\n",
              "      <td>2022-06-10 08:59:44.721000</td>\n",
              "      <td>(6106000954, 8344015827, 0)</td>\n",
              "      <td>789785997.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>footway</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1380552 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          _id  suitcase.id                    date.utc  \\\n",
              "0        RLftkn8B6D05RDJPRFzw          101  2022-03-16 13:31:23.556000   \n",
              "1        2rftkn8B6D05RDJPg1zA          101  2022-03-16 13:31:40.397000   \n",
              "2        7Lftkn8B6D05RDJPilxI           84  2022-03-16 13:31:42.588000   \n",
              "3        r_Ttkn8BECWPrCgui1Ov          102  2022-03-16 13:18:31.370000   \n",
              "4        Abftkn8B6D05RDJPkl0B           84  2022-03-16 13:31:44.839000   \n",
              "...                       ...          ...                         ...   \n",
              "1380547  GdQwSIEB6D05RDJPRgFx          110  2022-06-09 11:18:30.202000   \n",
              "1380548  HdQwSIEB6D05RDJPRwGz          107  2022-06-09 11:18:34.652000   \n",
              "1380549  i7MwSIEBjBK6gFa3V62V          105  2022-06-09 11:16:05.803000   \n",
              "1380550  5hHYTIEBECWPrCguIrVd           70  2022-06-10 09:00:06.043000   \n",
              "1380551  u7fXTIEBjBK6gFa3lpXL           84  2022-06-10 08:59:44.721000   \n",
              "\n",
              "                             edge.id   edge.osmid place.id   osm.highway   1  \\\n",
              "0          (66861445, 5777577020, 0)  148827821.0      NaN     secondary   0   \n",
              "1         (4784490177, 879290314, 0)  249810956.0      NaN     secondary   0   \n",
              "2        (5024071332, 2468498684, 0)  148744643.0      NaN       footway   0   \n",
              "3          (131242325, 366524790, 0)   25371931.0      NaN       footway   0   \n",
              "4        (4112634135, 6927774285, 0)  680591900.0      NaN     secondary   0   \n",
              "...                              ...          ...      ...           ...  ..   \n",
              "1380547  (8859143893, 7271978688, 0)  218421857.0      NaN   residential   0   \n",
              "1380548    (392518067, 121526083, 0)   25307428.0      NaN      tertiary   0   \n",
              "1380549   (190115287, 9768290867, 0)  182402103.0      NaN  unclassified  12   \n",
              "1380550   (6238636487, 231741978, 0)  794466424.0      NaN     secondary   3   \n",
              "1380551  (6106000954, 8344015827, 0)  789785997.0      NaN       footway   0   \n",
              "\n",
              "         2  3   4  5  7  8  10  13  14  16  19  21  25  26  27  28  29  30  \\\n",
              "0        0  0   0  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "1        0  0   0  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "2        0  0   0  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "3        3  1   0  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "4        1  0   5  0  0  1   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "...     .. ..  .. .. .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
              "1380547  0  0   2  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "1380548  0  1   3  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "1380549  0  3  22  0  0  0   0   0   0   1   0   0   0   0   0   0   0   0   \n",
              "1380550  0  3   1  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "1380551  0  0   0  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
              "\n",
              "         31  32  33  35  36  37  39  49  61  63  \n",
              "0         0   0   0   0   0   0   0   0   0   0  \n",
              "1         0   0   0   0   0   0   0   0   0   0  \n",
              "2         0   0   0   0   0   0   0   0   0   0  \n",
              "3         0   0   0   0   0   0   0   0   0   0  \n",
              "4         0   0   1   0   0   0   0   0   0   0  \n",
              "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
              "1380547   0   0   0   0   0   0   0   0   0   0  \n",
              "1380548   0   0   0   0   0   0   0   0   0   0  \n",
              "1380549   0   0   1   1   0   1   0   0   1   0  \n",
              "1380550   0   0   0   0   0   0   0   0   0   1  \n",
              "1380551   0   0   1   0   0   0   0   0   0   0  \n",
              "\n",
              "[1380552 rows x 36 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mwuMfTIH2A0"
      },
      "source": [
        "### Clean and Add Features to Main Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C6HwKXMH2A1",
        "outputId": "1d9f63da-7e53-4c27-e289-92b1a8c25aec"
      },
      "outputs": [],
      "source": [
        "df_main = data_processor.clean_df(df_main)\n",
        "df_main = data_processor.aggregate_df(df_main)\n",
        "df_main = data_processor.create_date_features(df_main)\n",
        "df_main = data_processor.create_coordinates_features(df_main)\n",
        "df_main = data_processor.create_weather_features(df_main)\n",
        "df_main = data_processor.create_osm_features(df_main)\n",
        "osm_columns = data_processor.create_osm_columns()\n",
        "# Runtime ~4 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ucY8ucAyuhS"
      },
      "source": [
        "### Add Features to Darkzones Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9oyBxaSyq2-",
        "outputId": "0cb1a094-fcfa-46a4-f14a-eb4f5dab2d75"
      },
      "outputs": [],
      "source": [
        "df_darkzones = data_processor.create_date_features(df_darkzones)\n",
        "df_darkzones = data_processor.create_coordinates_features(df_darkzones)\n",
        "df_darkzones = data_processor.create_weather_features(df_darkzones)\n",
        "df_darkzones = data_processor.create_osm_features(df_darkzones)\n",
        "# Runtime ~3 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-benuCsH2A6"
      },
      "source": [
        "# Poission Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2yUFMQMLH2A7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import PoissonRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcRND-xHH2A8"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OyUnqjdYH2A9"
      },
      "outputs": [],
      "source": [
        "def train_test(df, output):\n",
        "    columns_to_drop = ['total_litter', 'total_litter_ratio']\n",
        "    columns_to_drop.extend(data_processor.get_litter_columns(df))\n",
        "    X = df_main.drop(columns=columns_to_drop, errors='ignore')\n",
        "    y = df_main[output]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def train_poisson_model(df, output):\n",
        "    start_time = time.time()  # <-- Just to count how long the model takes to predict\n",
        "    X_train, X_test, y_train, y_test = train_test(df, output)\n",
        "\n",
        "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    numeric_features = X_train.select_dtypes(include=['int', 'float']).columns.tolist()\n",
        "    categorical_transformer = Pipeline(steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
        "    numeric_transformer = Pipeline(steps=[(\"scaler\", RobustScaler())])\n",
        "    preprocessor = ColumnTransformer(transformers=[(\"num\", numeric_transformer, numeric_features),\n",
        "                                                   (\"cat\", categorical_transformer, categorical_features)])\n",
        "    model_poisson = PoissonRegressor()\n",
        "    pipeline_poisson = Pipeline(steps=[(\"pre_process\", preprocessor), (\"poisson_model\", model_poisson)])\n",
        "    grid_search_poisson = {'poisson_model__alpha' : [1e-12],\n",
        "                           'poisson_model__max_iter' : [500]}\n",
        "    model_poisson = GridSearchCV(estimator=pipeline_poisson, param_grid=grid_search_poisson,\n",
        "                                scoring='neg_mean_poisson_deviance', verbose=7, n_jobs=-1)\n",
        "    model_poisson.fit(X_train, y_train)\n",
        "    best_model_poisson = model_poisson.best_estimator_\n",
        "    y_pred_poisson = best_model_poisson.predict(X_test)\n",
        "    y_pred_poisson = y_pred_poisson.astype(int)\n",
        "    time2train = round((time.time() - start_time)/60, 1)\n",
        "    print(f\"The fitting took: {time2train} minutes\")\n",
        "    score = best_model_poisson.score(X_test, y_test)\n",
        "    print(f'Litter {output} D2 Score: {score}')\n",
        "    print(f'#################################')\n",
        "    return best_model_poisson, X_test, y_test, time2train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NusuNpuBKFfI"
      },
      "outputs": [],
      "source": [
        "def make_models(df):\n",
        "    models = {}\n",
        "    litters = data_processor.get_litter_columns(df_main)\n",
        "    litters.extend(['total_litter'])\n",
        "    for litter in litters:\n",
        "        model, X_test, y_test, time2train = train_poisson_model(df, litter)\n",
        "        score = round(model.score(X_test, y_test), 4)\n",
        "        models[litter] = [model, y_test, score, time2train]\n",
        "    return models, X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhRChXE8xotc"
      },
      "source": [
        "## Prediction Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eU68V8LRbVZT"
      },
      "outputs": [],
      "source": [
        "litter_labels = [['1', 'Cigarette'],['2', 'Leaf'],['3', 'Leaves'],['4', 'Paper/Carton'],['5', 'CAN'],['7', 'Glass bottle'],['8', 'PET'],['9', 'Carton drink'],\n",
        "                ['10', 'FF Cup'],['11', 'FF Foam Polystrene'],['12', 'Other Foam Polystrene'],['13', 'Food packaging'],['14', 'Newspaper'],['15', 'Small bag'],\n",
        "                ['16', 'Glass Splinter'],['17', 'Syringe'],['18', 'Organic food littering'],['19', 'Dog fouling'],['21', 'Garbage bags'],['22', 'Sand/Grit/Granulate'],\n",
        "                ['23', 'Chewing- gum'],['24', 'Vomit'],['25', 'FF Cup'],['26', 'FF Lid'],['27', 'FF Straw'],['28', 'FF Fries cartin'],['29', 'Unclear bottles'],\n",
        "                ['30', 'FF Burger Box'],['31', 'FF Paper'],['32', 'FF Other Paper'],['33', 'iQos'],['34', 'Confettis (pile)'],['35', 'Medium/big stain'],\n",
        "                ['36', 'Transparent plastic'],['37', 'Opaque plastic'],['38', 'Fabric'],['39', 'Unrecognizable'],['40', 'Capsule'],['41', 'Carcass'],['42', 'Furniture'],\n",
        "                ['43', 'Tag'],['44', 'Poster'],['45', 'Waste bin stain'],['46', 'Waste bin tag'],['47', 'Waste bin sticker'],['48', 'Waste bin Ouverture'],['49', 'Waste bin'],\n",
        "                ['50', 'Cigarette white'],['51', 'Cigarette rolled'],['52', 'Cigarette unknown'],['53', 'Waste container too full'],['54', 'Illegal advertising poster'],\n",
        "                ['55', 'Illegal advertising poster (influenceable)'],['56', 'Illegal litters'],['57', 'Spray painting, graffiti'],['58', 'Spray painting, graffiti (influenceable)'],\n",
        "                ['59', 'Feuille mouillée'],['60', 'Poubelles remplies'],['61', 'Robydog'],['62', 'Wooden or plastic crate'],['63', 'Mask'],['total_litter', 'Total Litter']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0fHbIzXxKmL",
        "outputId": "1fb2343d-5834-422d-b5ba-dd59b6226f86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.3 minutes\n",
            "Litter 1 D2 Score: 0.5946284324918871\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.2 minutes\n",
            "Litter 2 D2 Score: 0.6701196870573678\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.2 minutes\n",
            "Litter 3 D2 Score: 0.45336086087467586\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.2 minutes\n",
            "Litter 4 D2 Score: 0.655981500570578\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.1 minutes\n",
            "Litter 5 D2 Score: 0.38622222769595016\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.0 minutes\n",
            "Litter 7 D2 Score: 0.25838683279754615\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.1 minutes\n",
            "Litter 8 D2 Score: 0.3913179975633959\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.2 minutes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:417: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return 1 - dev / dev_null\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Litter 10 D2 Score: -inf\n",
            "#################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:417: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return 1 - dev / dev_null\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.2 minutes\n",
            "Litter 13 D2 Score: -0.0014397161272337033\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 1.7 minutes\n",
            "Litter 14 D2 Score: 0.3038886349666077\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.0 minutes\n",
            "Litter 16 D2 Score: 0.3575343251830517\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.1 minutes\n",
            "Litter 19 D2 Score: 0.47143165426680755\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.1 minutes\n",
            "Litter 21 D2 Score: 0.6725325156429542\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.3 minutes\n",
            "Litter 25 D2 Score: 0.1069621240851093\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.3 minutes\n",
            "Litter 26 D2 Score: 0.018310039741767592\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.9 minutes\n",
            "Litter 27 D2 Score: 0.1820336649710017\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.2 minutes\n",
            "Litter 28 D2 Score: 0.019667002305008507\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.2 minutes\n",
            "Litter 29 D2 Score: 0.0031808852106278707\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.3 minutes\n",
            "Litter 30 D2 Score: 0.13934316186940876\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.2 minutes\n",
            "Litter 31 D2 Score: -0.010178880102289067\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.4 minutes\n",
            "Litter 32 D2 Score: 0.09791363854059787\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.1 minutes\n",
            "Litter 33 D2 Score: 0.46232633801295375\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.1 minutes\n",
            "Litter 35 D2 Score: 0.4244996034567631\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "The fitting took: 0.5 minutes\n",
            "Litter 36 D2 Score: 0.2431812447163354\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.1 minutes\n",
            "Litter 37 D2 Score: 0.2716093643647055\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.1 minutes\n",
            "Litter 39 D2 Score: 0.45425624448094104\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.1 minutes\n",
            "Litter 49 D2 Score: 0.36318917240034054\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.1 minutes\n",
            "Litter 61 D2 Score: 0.47224833193263804\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.0 minutes\n",
            "Litter 63 D2 Score: 0.38381506919498276\n",
            "#################################\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitting took: 2.3 minutes\n",
            "Litter total_litter D2 Score: 0.6349679534877858\n",
            "#################################\n"
          ]
        }
      ],
      "source": [
        "models, X_test = make_models(df_main)\n",
        "\n",
        "for key, value in models.items():\n",
        "  for item in litter_labels:\n",
        "    if key == item[0]:\n",
        "      models[key].append(item[1])\n",
        "# Runtime ~3 minutes per litter and ~60 minutes for all litters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qmO_haGRbSD0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def train_test(df, output):\n",
        "    columns_to_drop = ['total_litter', 'total_litter_ratio']\n",
        "    columns_to_drop.extend(data_processor.get_litter_columns(df))\n",
        "    X = df_main.drop(columns=columns_to_drop, errors='ignore')\n",
        "    y = df_main[output]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test(df_main, '1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU3cuZ4wxxxB"
      },
      "source": [
        "# Predict Darkzones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kLcMTLIoFeSg"
      },
      "outputs": [],
      "source": [
        "litter_columns = data_processor.get_litter_columns(df_darkzones)\n",
        "\n",
        "for key, model in models.items():\n",
        "    predictions = model[0].predict(df_darkzones)\n",
        "    predictions = np.rint(predictions).astype(int)\n",
        "    df_darkzones[f\"{key}\"] = predictions\n",
        "\n",
        "columns_to_drop = ['Year', 'month', 'day', 'weekday', 'holiday', 'lat_north', 'lat_south', 'lon_east', 'lon_west', 'edge_length', \n",
        "        'temperature_max', 'temperature_min', 'temperature_mean', 'precipitation', 'snowfall', 'humidity_max', 'humidity_min', \n",
        "        'humidity_mean', 'cloud_coverage', 'wind_speed_max', 'wind_speed_min', 'wind_speed_mean']\n",
        "columns_to_drop.extend(osm_columns)\n",
        "df_darkzones.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
        "df_darkzones.rename(columns={'total_litter': 'predicted_total'}, inplace=True)\n",
        "df_darkzones['actual_total'] = df_darkzones[litter_columns].sum(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vU_hUvNv0e4"
      },
      "source": [
        "# Export Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9hEjLUc5v0e4"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('models_dictionary.pkl', 'wb') as f:\n",
        "    pickle.dump(models, f)\n",
        "# with open('models_dictionary.pkl', 'rb') as f:\n",
        "#     models = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-sdz7OXTv0e5"
      },
      "outputs": [],
      "source": [
        "X_test.to_csv(\"X_test.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "dominik_day_11_12_predict.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 ('cortexia3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "393eaa007fcd2c7a4c179b44934792a94932bcce71862c954e102a685fb04132"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
